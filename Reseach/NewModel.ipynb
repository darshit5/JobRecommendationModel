{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a88432-dbac-4896-a6eb-51e58ced988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from ftfy import fix_text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import skills_extraction as skills_extraction\n",
    "\n",
    "# Load dataset:\n",
    "jd_df = pd.read_csv(r'structuredpublic.csv')\n",
    "\n",
    "# Load the extracted resume skills:\n",
    "file_path = r'CV.pdf'\n",
    "skills = []\n",
    "skills.append(' '.join(word for word in skills_extraction.skills_extractor(file_path)))\n",
    "\n",
    "# Function to create ngrams\n",
    "def ngrams(string, n=3):\n",
    "    string = fix_text(string)  # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode()  # remove non-ascii chars\n",
    "    string = string.lower()\n",
    "    chars_to_remove = [\")\", \"(\", \".\", \"|\", \"[\", \"]\", \"{\", \"}\", \"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title()  # normalize case - capital at the start of each word\n",
    "    string = re.sub(' +', ' ', string).strip()  # get rid of multiple spaces and replace with a single\n",
    "    string = ' ' + string + ' '  # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD', r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "# vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "# tfidf = vectorizer.fit_transform(skills)\n",
    "# jd_test = jd_df['Processed_JD'].values.astype('U')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cb4bca-cf18-4c7f-b2e2-9a150e96a716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  0  0  0  2  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 34  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1 26  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  2  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0 40  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1 10  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  4  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]]\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                                -1       1.00      0.60      0.75        10\n",
      "                Accounting & Legal       0.00      0.00      0.00         1\n",
      "               Aerospace & Defense       1.00      0.83      0.91         6\n",
      "  Arts, Entertainment & Recreation       1.00      1.00      1.00         2\n",
      "         Biotech & Pharmaceuticals       0.92      1.00      0.96        34\n",
      "                 Business Services       0.96      0.84      0.90        31\n",
      "Construction, Repair & Maintenance       1.00      1.00      1.00         1\n",
      "                         Education       1.00      0.50      0.67         4\n",
      "                           Finance       0.91      0.71      0.80        14\n",
      "                        Government       1.00      0.50      0.67         4\n",
      "                       Health Care       1.00      1.00      1.00         9\n",
      "            Information Technology       0.67      0.98      0.79        41\n",
      "                         Insurance       1.00      0.83      0.91        12\n",
      "                     Manufacturing       0.80      0.80      0.80         5\n",
      "                             Media       1.00      0.50      0.67         2\n",
      "                   Mining & Metals       1.00      1.00      1.00         1\n",
      "                        Non-Profit       1.00      1.00      1.00         3\n",
      "      Oil, Gas, Energy & Utilities       1.00      1.00      1.00         3\n",
      "                       Real Estate       1.00      0.50      0.67         2\n",
      "                            Retail       1.00      1.00      1.00         2\n",
      "                Telecommunications       1.00      1.00      1.00         1\n",
      "        Transportation & Logistics       1.00      0.50      0.67         2\n",
      "                  Travel & Tourism       1.00      1.00      1.00         2\n",
      "\n",
      "                          accuracy                           0.86       192\n",
      "                         macro avg       0.92      0.79      0.83       192\n",
      "                      weighted avg       0.89      0.86      0.86       192\n",
      "\n",
      "Accuracy:  0.8645833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "\n",
    "# Assuming that your dataframe has a 'Labels' column that contains the labels for your data\n",
    "labels = jd_df['Sector'].values.astype('U')\n",
    "\n",
    "# Split the data into a training set and a testing set\n",
    "jd_train, jd_test, labels_train, labels_test = train_test_split(jd_df['processed_JD'].values.astype('U'), labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform the training and testing sets\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "jd_train_transformed = vectorizer.fit_transform(jd_train)\n",
    "jd_test_transformed = vectorizer.transform(jd_test)\n",
    "\n",
    "# Train the SVM model on the training set\n",
    "svm = LinearSVC()\n",
    "svm.fit(jd_train_transformed, labels_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(svm, 'svm_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "svm_loaded = joblib.load('svm_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions on the testing set\n",
    "labels_pred = svm_loaded.predict(jd_test_transformed)\n",
    "\n",
    "# Build a confusion matrix\n",
    "print(confusion_matrix(labels_test, labels_pred))\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "print(\"Accuracy: \", accuracy_score(labels_test, labels_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a43a92a-1f76-4023-9156-e9c51ed482ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0 33  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 31  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 41  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                                -1       0.00      0.00      0.00        10\n",
      "                Accounting & Legal       0.00      0.00      0.00         1\n",
      "               Aerospace & Defense       0.00      0.00      0.00         6\n",
      "  Arts, Entertainment & Recreation       0.00      0.00      0.00         2\n",
      "         Biotech & Pharmaceuticals       1.00      0.03      0.06        34\n",
      "                 Business Services       0.00      0.00      0.00        31\n",
      "Construction, Repair & Maintenance       0.00      0.00      0.00         1\n",
      "                         Education       0.00      0.00      0.00         4\n",
      "                           Finance       0.00      0.00      0.00        14\n",
      "                        Government       0.00      0.00      0.00         4\n",
      "                       Health Care       0.00      0.00      0.00         9\n",
      "            Information Technology       0.21      1.00      0.35        41\n",
      "                         Insurance       0.00      0.00      0.00        12\n",
      "                     Manufacturing       0.00      0.00      0.00         5\n",
      "                             Media       0.00      0.00      0.00         2\n",
      "                   Mining & Metals       0.00      0.00      0.00         1\n",
      "                        Non-Profit       0.00      0.00      0.00         3\n",
      "      Oil, Gas, Energy & Utilities       0.00      0.00      0.00         3\n",
      "                       Real Estate       0.00      0.00      0.00         2\n",
      "                            Retail       0.00      0.00      0.00         2\n",
      "                Telecommunications       0.00      0.00      0.00         1\n",
      "        Transportation & Logistics       0.00      0.00      0.00         2\n",
      "                  Travel & Tourism       0.00      0.00      0.00         2\n",
      "\n",
      "                          accuracy                           0.22       192\n",
      "                         macro avg       0.05      0.04      0.02       192\n",
      "                      weighted avg       0.22      0.22      0.09       192\n",
      "\n",
      "Accuracy:  0.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "################ naive bayes \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train the Naive Bayes model on the training set\n",
    "nb = MultinomialNB()\n",
    "nb.fit(jd_train_transformed, labels_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(nb, 'nb_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "nb_loaded = joblib.load('nb_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions on the testing set\n",
    "labels_pred = nb_loaded.predict(jd_test_transformed)\n",
    "\n",
    "# Build a confusion matrix\n",
    "print(confusion_matrix(labels_test, labels_pred))\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "print(\"Accuracy: \", accuracy_score(labels_test, labels_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4f8dd8-9c88-4c35-b0b8-7c60cb1bea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  0  0  3  3  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0 23  0  0  0  5  0  0  1  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 2  0  0  1  2 17  0  0  2  0  0  2  1  0  0  0  0  0  4  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  8  0  0  4  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  7  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  1  8  0  0  9  0  0 19  1  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  1  0  0  1  8  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  0  0  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0]]\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                                -1       0.38      0.30      0.33        10\n",
      "                Accounting & Legal       0.00      0.00      0.00         1\n",
      "               Aerospace & Defense       1.00      0.33      0.50         6\n",
      "  Arts, Entertainment & Recreation       0.67      1.00      0.80         2\n",
      "         Biotech & Pharmaceuticals       0.79      0.68      0.73        34\n",
      "                 Business Services       0.47      0.55      0.51        31\n",
      "Construction, Repair & Maintenance       1.00      1.00      1.00         1\n",
      "                         Education       0.00      0.00      0.00         4\n",
      "                           Finance       0.27      0.57      0.36        14\n",
      "                        Government       1.00      1.00      1.00         4\n",
      "                       Health Care       1.00      0.78      0.88         9\n",
      "            Information Technology       0.68      0.46      0.55        41\n",
      "                         Insurance       0.57      0.67      0.62        12\n",
      "                     Manufacturing       1.00      0.60      0.75         5\n",
      "                             Media       1.00      0.50      0.67         2\n",
      "                   Mining & Metals       0.00      0.00      0.00         1\n",
      "                        Non-Profit       1.00      1.00      1.00         3\n",
      "      Oil, Gas, Energy & Utilities       1.00      1.00      1.00         3\n",
      "                       Real Estate       0.06      0.50      0.11         2\n",
      "                            Retail       1.00      0.50      0.67         2\n",
      "                Telecommunications       1.00      1.00      1.00         1\n",
      "        Transportation & Logistics       0.00      0.00      0.00         2\n",
      "                  Travel & Tourism       0.00      0.00      0.00         2\n",
      "\n",
      "                          accuracy                           0.56       192\n",
      "                         macro avg       0.60      0.54      0.54       192\n",
      "                      weighted avg       0.63      0.56      0.57       192\n",
      "\n",
      "Accuracy:  0.5572916666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train the KNN model on the training set\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(jd_train_transformed, labels_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(knn, 'knn_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "knn_loaded = joblib.load('knn_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions on the testing set\n",
    "labels_pred = knn_loaded.predict(jd_test_transformed)\n",
    "\n",
    "# Build a confusion matrix\n",
    "print(confusion_matrix(labels_test, labels_pred))\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "print(\"Accuracy: \", accuracy_score(labels_test, labels_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4302893a-e8bc-47d8-9e57-b3374901229f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m jd_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSector\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets (80-20 ratio)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mtfidf\u001b[49m, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train the KNN model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m knn_model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# You can choose the number of neighbors as needed\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "# Assuming 'Sector' is the column you want to predict as a label\n",
    "labels = jd_df['Sector']\n",
    "\n",
    "# Split the data into training and testing sets (80-20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can choose the number of neighbors as needed\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25dbdbc-4990-4815-96da-098ce9f5a4f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 11524 while Y.shape[1] == 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m jd_vectors \u001b[38;5;241m=\u001b[39m jd_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(jd_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed_JD\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity  \u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjd_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskills_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m scores \u001b[38;5;241m=\u001b[39m similarity[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Get top 5 most similar JDs\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1577\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \n\u001b[0;32m   1544\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;124;03m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1577\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1579\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mC:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:190\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed metric requires shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(n_queries, n_indexed). Got (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m indexed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    188\u001b[0m         )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimension for X and Y matrices: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m while Y.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, Y\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 11524 while Y.shape[1] == 12"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import skills_extraction\n",
    "\n",
    "# Load dataset \n",
    "jd_df = pd.read_csv('jd_structured_data.csv')\n",
    "\n",
    "# Extract skills from resume\n",
    "\n",
    "file_path = r'CV.pdf'\n",
    "extracted_skills = []\n",
    "extracted_skills.append(' '.join(word for word in skills_extraction.skills_extractor(file_path)))\n",
    "\n",
    "# Vectorizer for skills\n",
    "skills_vectorizer = TfidfVectorizer()\n",
    "skills_vectors = skills_vectorizer.fit_transform(extracted_skills)\n",
    "\n",
    "# Vectorize job descriptions \n",
    "jd_vectorizer = TfidfVectorizer()\n",
    "jd_vectors = jd_vectorizer.fit_transform(jd_df['Processed_JD'])\n",
    "\n",
    "# Compute cosine similarity  \n",
    "similarity = cosine_similarity(jd_vectors, skills_vectors)\n",
    "scores = similarity[0]\n",
    "\n",
    "# Get top 5 most similar JDs\n",
    "top_indices = scores.argsort()[-5:][::-1]\n",
    "recommended_jds = jd_df.iloc[top_indices]\n",
    "\n",
    "print('Recommended Jobs:')\n",
    "print(recommended_jds['Job_Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f86e763-52a5-4dd9-9399-b39cdbfcb0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 28  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 14  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  4  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0 47  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3 12  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  8  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  1]]\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "         Aerospace & Defense       1.00      0.50      0.67         4\n",
      "      Agriculture & Forestry       0.00      0.00      0.00         1\n",
      "   Biotech & Pharmaceuticals       1.00      0.97      0.98        29\n",
      "           Business Services       0.82      0.45      0.58        31\n",
      "                   Education       1.00      0.56      0.71         9\n",
      "                     Finance       0.88      1.00      0.93         7\n",
      "                  Government       1.00      0.67      0.80         3\n",
      "                 Health Care       1.00      0.62      0.76        13\n",
      "      Information Technology       0.56      0.98      0.71        48\n",
      "                   Insurance       1.00      0.80      0.89        15\n",
      "               Manufacturing       1.00      0.89      0.94         9\n",
      "                       Media       0.00      0.00      0.00         1\n",
      "             Mining & Metals       0.00      0.00      0.00         1\n",
      "                  Non-Profit       0.75      1.00      0.86         3\n",
      "Oil, Gas, Energy & Utilities       1.00      1.00      1.00         3\n",
      "                 Real Estate       1.00      1.00      1.00         1\n",
      "          Telecommunications       1.00      1.00      1.00         1\n",
      "  Transportation & Logistics       0.00      0.00      0.00         2\n",
      "            Travel & Tourism       1.00      0.33      0.50         3\n",
      "\n",
      "                    accuracy                           0.77       184\n",
      "                   macro avg       0.74      0.62      0.65       184\n",
      "                weighted avg       0.82      0.77      0.76       184\n",
      "\n",
      "Accuracy:  0.7717391304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from ftfy import fix_text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import skills_extraction as skills_extraction\n",
    "\n",
    "jd_df = pd.read_csv(r'jd_structured_data.csv')\n",
    "file_path = r'CV.pdf'\n",
    "skills = []\n",
    "skills.append(' '.join(word for word in skills_extraction.skills_extractor(file_path)))\n",
    "\n",
    "def ngrams(string, n=3):\n",
    "    string = fix_text(string)  # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode()  # remove non-ascii chars\n",
    "    string = string.lower()\n",
    "    chars_to_remove = [\")\", \"(\", \".\", \"|\", \"[\", \"]\", \"{\", \"}\", \"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title()  # normalize case - capital at the start of each word\n",
    "    string = re.sub(' +', ' ', string).strip()  # get rid of multiple spaces and replace with a single\n",
    "    string = ' ' + string + ' '  # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD', r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "    # ... same as your previous code ...\n",
    "\n",
    "labels = jd_df['Sector'].values.astype('U')\n",
    "jd_train, jd_test, labels_train, labels_test = train_test_split(jd_df['Processed_JD'].values.astype('U'), labels, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "jd_train_transformed = vectorizer.fit_transform(jd_train)\n",
    "jd_test_transformed = vectorizer.transform(jd_test)\n",
    "\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(jd_train_transformed, labels_train)\n",
    "\n",
    "joblib.dump(rfc, 'rfc_model.pkl')\n",
    "\n",
    "rfc_loaded = joblib.load('rfc_model.pkl')\n",
    "labels_pred = rfc_loaded.predict(jd_test_transformed)\n",
    "\n",
    "print(confusion_matrix(labels_test, labels_pred))\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "print(\"Accuracy: \", accuracy_score(labels_test, labels_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fe64d-e5c1-49f7-bf8b-6e6d39bc63cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
